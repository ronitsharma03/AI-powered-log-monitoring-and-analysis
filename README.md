# ğŸš€ AI-Powered Log Monitoring & Analysis System

## ğŸ“Œ Project Overview
This project is an **AI-powered log monitoring and analysis system** designed for **Veritas** to automate the detection and contextual analysis of error logs. It enhances **system reliability** and **incident response efficiency** by leveraging **machine learning**, **log queueing**, and **real-time WebSocket communication**.

---

## ğŸ¯ Key Features
âœ… **Automated Log Collection** â€“ Monitors critical log files for real-time updates.  
âœ… **AI-Based Log Analysis** â€“ Uses an LLM (Large Language Model) to analyze logs.  
âœ… **Queue-Based Processing** â€“ Logs are sent to a Redis queue for asynchronous handling.  
âœ… **PostgreSQL Storage** â€“ Stores logs and their AI-generated insights for retrieval.  
âœ… **WebSocket Communication** â€“ Primary backend and worker communicate efficiently over WebSockets.  
âœ… **Scalable Architecture** â€“ Easily extendable to monitor additional logs or integrate new AI models.  

---

## ğŸ—ï¸ Project Architecture
```mermaid
flowchart LR
    subgraph Primary Backend
        A[Log Collector] --> |Push Logs| B(Redis Queue)
    end
    
    subgraph Worker
        B --> |Fetch Logs| C(Log Processor)
        C --> |Analyze Logs| D(LLM)
        D --> |Store Analysis| E(PostgreSQL)
    end
    
    subgraph Frontend
        F[User] --> |Fetch Analyzed Logs| G(Primary Backend API)
        G --> |Retrieve from DB| E
    end
```

---

## âš™ï¸ Tech Stack
- **Backend**: Node.js, Express.js
- **Worker**: Node.js, Prisma, WebSockets
- **Database**: PostgreSQL
- **Queue**: Redis
- **AI Model**: Large Language Model (LLM)

---

## ğŸ“‚ Folder Structure
```
backend/
â”œâ”€â”€ primary-backend/                # Primary Backend (Express API, Log Collection, WebSockets)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ controllers/            # Handles API logic
â”‚   â”‚   â”œâ”€â”€ services/               # Business logic for log processing
â”‚   â”‚   â”œâ”€â”€ routes/                 # API Routes
â”‚   â”‚   â”œâ”€â”€ app.ts                  # Main entry point
â”‚   â”œâ”€â”€ dist/                       # Compiled TypeScript
â”‚   â””â”€â”€ package.json                # Dependencies & scripts
â””â”€â”€ log-processor/                  # Worker (Log queue processing, LLM interaction)
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ services/               # Queue consumption, LLM processing
    â”‚   â”œâ”€â”€ workers/                # Worker logic
    â”‚   â”œâ”€â”€ app.ts                  # Main entry for worker
    â”œâ”€â”€ dist/
    â””â”€â”€ package.json
```

---

## ğŸš€ Setup & Installation
### 1ï¸âƒ£ Clone the Repository
```sh
git clone https://github.com/your-username/log-monitoring-ai.git
cd log-monitoring-ai
```
### 2ï¸âƒ£ Install Dependencies
```sh
cd backend/primary-backend
npm install

cd ../log-processor
npm install
```
### 3ï¸âƒ£ Set Up Environment Variables
Create a `.env` file in both **primary-backend** and **log-processor** directories.
```env
# PostgreSQL Database
DATABASE_URL=postgresql://user:password@localhost:5432/logs_db

# Redis Configuration
REDIS_HOST=localhost
REDIS_PORT=6379

# WebSocket Configuration
WS_SERVER_URL=ws://localhost:4000
```
### 4ï¸âƒ£ Start the Services
#### Start Redis (if not running)
```sh
redis-server
```
#### Start Primary Backend
```sh
cd backend/primary-backend
npm run dev
```
#### Start Worker (Log Processor)
```sh
cd backend/log-processor
npm run dev
```

---

## ğŸ“Š How It Works
1ï¸âƒ£ **Logs are collected** from specified system directories.  
2ï¸âƒ£ **Primary backend pushes logs** to the Redis queue.  
3ï¸âƒ£ **Worker fetches logs** from Redis, sends them to an **LLM for analysis**.  
4ï¸âƒ£ **Analyzed logs are stored** in PostgreSQL.  
5ï¸âƒ£ **Frontend fetches logs** via API/WebSockets for real-time monitoring.  

---

## ğŸ”¥ Future Enhancements
- [ ] **Alert System**: Trigger real-time alerts for critical errors.
- [ ] **Dashboard**: Build a UI for visualizing logs and analytics.
- [ ] **Multi-Source Integration**: Monitor logs from cloud services.

---

## ğŸ¤ Contributing
Contributions are welcome! Feel free to open an **issue** or submit a **pull request**. 

---

## ğŸ“œ License
This project is licensed under the **MIT License**. See [LICENSE](./LICENSE) for details.

---

## ğŸ“ Contact
For any queries, reach out to **Your Name** at [your-email@example.com](mailto:your-email@example.com).
